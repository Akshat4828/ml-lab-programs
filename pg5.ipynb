{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Name: Hanush Gowrav Gowda K S <br>\n",
    "USN: 1JB17CS051<br><br>\n",
    "Program: 5<br>\n",
    "Assignment: 6</h5><h6>(Program 5- Naïve Bayesian)</h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>1. Program to implement the Naïve Bayesian Classifier for a sample training data set stored as a .CSV file.</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename,\"r\"))\n",
    "    dataset=list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i]=[float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "# Splitting the Data set into Training Set\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy)) # random index\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "#Create a dictionary of classes 1 and 0 where the values are the instacnes belonging to each class\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector=dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg=mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "#zip(\"res) transposes a matrix (2-d array/list)\n",
    "    del summaries[-1] # Exclude label\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated=separateByClass(dataset)\n",
    "    summaries ={} # to store mean and std of +ve and -ve instances\n",
    "    for classValue, instances in separated.items(): #summaries is a dictionary of tuples(mean,std) for each class value\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "#For continuous attributes p is estimated using Gaussion distribution\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1/ (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    #class and attribute information as mean and sd\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i] \n",
    "            x=inputVector[i] #inputvector's first attribute use normal distribution\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities      \n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb= None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        #assigns that class which has he highest prob\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions=[]\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1]== predictions[i]:\n",
    "            correct +=1\n",
    "    return (float(correct)/float(len(testSet)))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The length of the Data Set :  768\n",
      "\n",
      " The Data Set Splitting into Training and Testing \n",
      "\n",
      "\n",
      " The length of the Traning Set :  460\n",
      "\n",
      " The length of the Testing Set :  308\n",
      "\n",
      "Predictions:\n",
      " [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "\n",
      " Accuracy: 75.32467532467533%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filename = 'Hanush\\pgrm5.csv'\n",
    "    dataset = loadCsv(filename)\n",
    "    splitRatio = 0.6\n",
    "    #print(\"\\n The Data Set :\\n\",dataset)\n",
    "    print(\"\\n The length of the Data Set : \",len(dataset))\n",
    "\n",
    "    print(\"\\n The Data Set Splitting into Training and Testing \\n\")\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    print(\"\\n The length of the Traning Set : \",len(trainingSet))\n",
    "    print(\"\\n The length of the Testing Set : \",len(testSet))\n",
    "    \n",
    "    # prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "   \n",
    "    # test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    print(\"\\nPredictions:\\n\",predictions)\n",
    "    \n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('\\n Accuracy: {0}%'.format(accuracy))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>2. Naïve Bayesian Classifier on breast cancer dataset</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy matrices\n",
      "Accuracy of the classifier is 0.9473684210526315\n",
      "Consuion matrices\n",
      "[[38  4]\n",
      " [ 2 70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y=dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.2, random_state=1)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "classifier = gnb.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print('Accuracy matrices')\n",
    "print('Accuracy of the classifier is', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Consuion matrices')\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
